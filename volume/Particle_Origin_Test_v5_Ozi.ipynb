{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "import gammapy\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in multiply\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in less\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import click\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import naima\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import Angle, SkyCoord, EarthLocation, AltAz\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve\n",
    "from pathlib import Path\n",
    "from regions import CircleSkyRegion\n",
    "import itertools\n",
    "import psutil\n",
    "from scipy.stats import norm\n",
    "\n",
    "from gammapy.irf import load_cta_irfs\n",
    "from gammapy.maps import WcsGeom, MapAxis, WcsNDMap, Map\n",
    "from gammapy.modeling.models import PowerLawSpectralModel, ExpCutoffPowerLawSpectralModel, PowerLawNormSpectralModel, NaimaSpectralModel, LogParabolaSpectralModel\n",
    "from gammapy.modeling.models import PointSpatialModel, GaussianSpatialModel\n",
    "from gammapy.modeling.models import SkyModel, BackgroundModel, FoVBackgroundModel \n",
    "from gammapy.modeling.models import Models, TemplateSpatialModel #SkyDiffuseCube\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.data import Observation\n",
    "from gammapy.datasets import MapDataset\n",
    "from gammapy.makers import MapDatasetMaker, SafeMaskMaker\n",
    "from gammapy.estimators import ExcessMapEstimator\n",
    "from gammapy.datasets import (\n",
    "    Datasets,\n",
    "    SpectrumDataset,\n",
    "    SpectrumDatasetOnOff,\n",
    "    FluxPointsDataset,\n",
    ")\n",
    "from gammapy.estimators import FluxPoints\n",
    "from gammapy.estimators import FluxPointsEstimator\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install h5py\n",
    "\n",
    "!conda run -n gammapy conda install psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cta_irfs(ra, dec):\n",
    "    \"\"\"Prepares CTA irfs\"\"\"\n",
    "    log.info(\"        Preparing CTA IRFs\")\n",
    "    spatial_model_position_sim = SkyCoord(ra * u.deg, dec * u.deg, frame='icrs') # OBS POS!\n",
    "    energy_axis = MapAxis.from_edges(\n",
    "        np.logspace(-1, 2.2, 31), unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    "    )\n",
    "    energy_axis_true = MapAxis.from_edges(\n",
    "        np.logspace(-1.5, 2.3, 62), unit=\"TeV\", name=\"energy_true\", interp=\"log\"\n",
    "    )\n",
    "\n",
    "    geom = WcsGeom.create(\n",
    "        skydir=spatial_model_position_sim, binsz=0.02, width=(3, 3), frame=\"icrs\", axes=[energy_axis]\n",
    "    )\n",
    "\n",
    "    # Create an in-memory observation\n",
    "    POINTING = SkyCoord(ra * u.deg, dec * u.deg + offset, frame='icrs', unit='deg')\n",
    "    obs = Observation.create(pointing=POINTING, livetime=LIVETIME, irfs=irfs)\n",
    "    # Make the MapDataset\n",
    "    empty = MapDataset.create(geom, energy_axis_true=energy_axis_true, name=\"dataset-simu\")\n",
    "    maker = MapDatasetMaker(selection=[\"exposure\", \"background\", \"psf\", \"edisp\"])\n",
    "    maker_safe_mask = SafeMaskMaker(methods=[\"offset-max\"], offset_max=4.0 * u.deg)\n",
    "    dataset = maker.run(empty, obs)\n",
    "    dataset = maker_safe_mask.run(dataset, obs)\n",
    "\n",
    "    exposure = dataset.exposure\n",
    "    background_model = dataset.background_model\n",
    "    psf = dataset.psf\n",
    "    edisp = dataset.edisp\n",
    "    bkg_model = FoVBackgroundModel(dataset_name=\"dataset-simu\")\n",
    "\n",
    "    return dataset, exposure, bkg_model, psf, edisp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_spatial_models(ra, dec, extension):\n",
    "    \"\"\"Defines simulated and fitted skymodels\"\"\"\n",
    "        # Simulated models\n",
    "\n",
    "    if(extension > 0.0):\n",
    "        \n",
    "        spatial_model_sim = GaussianSpatialModel(lon_0= ra * u.deg, lat_0= dec * u.deg, sigma= extension * u.deg)\n",
    "       \n",
    "        spatial_model_fit = GaussianSpatialModel(lon_0= ra * u.deg, lat_0= dec * u.deg, sigma= 0.2 * u.deg)\n",
    "        spatial_model_fit.sigma.frozen = False\n",
    "        spatial_model_fit.sigma.min = 0.05\n",
    "        spatial_model_fit.sigma.max = spatial_model_fit.lat_0.value + 0.3\n",
    "\n",
    "    else:\n",
    "        \n",
    "        spatial_model_sim = PointSpatialModel(lon_0= ra * u.deg, lat_0= dec * u.deg)\n",
    "        spatial_model_fit = PointSpatialModel(lon_0= ra * u.deg, lat_0= dec * u.deg)\n",
    "\n",
    "    spatial_model_fit.lon_0.frozen = False\n",
    "    spatial_model_fit.lat_0.frozen = False\n",
    "\n",
    "    spatial_model_fit.lon_0.min = spatial_model_fit.lon_0.value - 0.2\n",
    "    spatial_model_fit.lon_0.max = spatial_model_fit.lon_0.value + 0.2\n",
    "    spatial_model_fit.lat_0.min = spatial_model_fit.lat_0.value - 0.2\n",
    "    spatial_model_fit.lat_0.max = spatial_model_fit.lat_0.value + 0.2\n",
    "\n",
    "    return spatial_model_sim, spatial_model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gammaray_fit_models():\n",
    "    \"\"\"Returns gamma-ray spectral models\"\"\"\n",
    "\n",
    "    # Powerlaw model                                                                                                                                                                                   \n",
    "    spectral_model_pl_fit = PowerLawSpectralModel(index=2.0, amplitude=\"2.0e-12 cm-2 s-1 TeV-1\", reference=\"1 TeV\")\n",
    "    spectral_model_pl_fit.amplitude.min = 1e-17\n",
    "    spectral_model_pl_fit.amplitude.max = 1e-5\n",
    "    spectral_model_pl_fit.reference.frozen = True\n",
    "    spectral_model_pl_fit.index.min = 0.0\n",
    "    spectral_model_pl_fit.index.max = 4.0\n",
    "\n",
    "    # ECPL model                                                                                                                                                                                       \n",
    "    spectral_model_ecpl_fit = ExpCutoffPowerLawSpectralModel(index=2.0, amplitude=\"2.0e-12 cm-2 s-1 TeV-1\", reference=\"1 TeV\", lambda_=\"0.01 TeV-1\", alpha=1.0)\n",
    "    spectral_model_ecpl_fit.amplitude.min = 1e-17\n",
    "    spectral_model_ecpl_fit.amplitude.max = 1e-5\n",
    "    spectral_model_ecpl_fit.index.min = 0.0\n",
    "    spectral_model_ecpl_fit.index.max = 4.0\n",
    "    spectral_model_ecpl_fit.reference.frozen = True\n",
    "    spectral_model_ecpl_fit.alpha.frozen = True\n",
    "    spectral_model_ecpl_fit.lambda_.frozen = False\n",
    "        \n",
    "    #LogParabola model\n",
    "    spectral_model_lpb_fit = LogParabolaSpectralModel(alpha=2.3, amplitude=\"1e-12 cm-2 s-1 TeV-1\", reference=1 * u.TeV, beta=0.5)\n",
    "    spectral_model_lpb_fit.amplitude.min = 1e-17\n",
    "    spectral_model_lpb_fit.amplitude.max = 1e-5\n",
    "    spectral_model_lpb_fit.alpha.min = 0.0\n",
    "    spectral_model_lpb_fit.alpha.max = 4.0\n",
    "    spectral_model_lpb_fit.beta.min  = -5.0 # Not sure if its a reasonable choice! Check later!\n",
    "    spectral_model_lpb_fit.beta.max  = 5.0\n",
    "    spectral_model_lpb_fit.reference.frozen = True\n",
    "\n",
    "    return spectral_model_pl_fit, spectral_model_ecpl_fit, spectral_model_lpb_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_particle_model(particle_type, spect_type, norm, index, cutoff, distance, ngas, seed_photon, ep_max, ee_max):\n",
    "    \n",
    "    if(particle_type == 'Had'):\n",
    "        \n",
    "        normalized_proton_spect = normalize_proton_model(spect_type, norm, index, cutoff, distance, ngas, ep_max)\n",
    "        nh = ngas / u.cm**3\n",
    "        \n",
    "        if(spect_type == 'ECPL'):\n",
    "            proton_distribution_sim = naima.models.ExponentialCutoffPowerLawH(\n",
    "                amplitude=normalized_proton_spect.parameters[\"amplitudeH\"].value / u.eV, \n",
    "                e_0=10 * u.TeV, \n",
    "                alpha=index, \n",
    "                lambda_=(1/cutoff) / u.TeV\n",
    "            )\n",
    "\n",
    "        else:\n",
    "                proton_distribution_sim = naima.models.PowerLaw(\n",
    "                amplitude=normalized_proton_spect.parameters[\"amplitude\"].value / u.eV, \n",
    "                e_0=10 * u.TeV, \n",
    "                alpha=index, \n",
    "            )\n",
    "            \n",
    "\n",
    "        radiative_model_fit = naima.radiative.PionDecay(\n",
    "            proton_distribution_sim,\n",
    "            nh = nh,\n",
    "            Epmax = ep_max,\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        normalized_electron_spect = normalize_electron_model(spect_type, norm, index, cutoff, distance, seed_photon, ee_max)\n",
    "\n",
    "        seed_photon_fields = seed_photon \n",
    "        \n",
    "        if(spect_type == 'ECPL'):\n",
    "\n",
    "            electron_distribution_sim = naima.models.ExponentialCutoffPowerLawL(\n",
    "                amplitude=normalized_electron_spect.parameters[\"amplitudeL\"].value / u.eV, \n",
    "                e_0=1 * u.TeV, \n",
    "                alpha=index, \n",
    "                lambda_=(1/cutoff) / u.TeV\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            \n",
    "                electron_distribution_sim = naima.models.PowerLaw(\n",
    "                amplitude=normalized_electron_spect.parameters[\"amplitude\"].value / u.eV, \n",
    "                e_0=1 * u.TeV, \n",
    "                alpha=index, \n",
    "            )\n",
    "\n",
    "        radiative_model_fit = naima.radiative.InverseCompton(\n",
    "            electron_distribution_sim,\n",
    "            seed_photon_fields = seed_photon,\n",
    "            Eemax = ee_max\n",
    "        )\n",
    "    \n",
    "    distance = distance * u.kpc    \n",
    "    particle_gamma_fit_model = NaimaSpectralModel(radiative_model_fit, distance=distance)\n",
    "    \n",
    "    if particle_type == 'Had':\n",
    "        particle_gamma_fit_model.parameters[\"e_0H\"].frozen = True\n",
    "        particle_gamma_fit_model.parameters[\"alphaH\"].min = 1.0\n",
    "        particle_gamma_fit_model.parameters[\"alphaH\"].max = 5.0\n",
    "        particle_gamma_fit_model.parameters[\"amplitudeH\"].min = 0\n",
    "    \n",
    "        if(spect_type == 'ECPL'):\n",
    "            particle_gamma_fit_model.parameters[\"betaH\"].frozen = True\n",
    "            particle_gamma_fit_model.parameters[\"betaH\"].frozen = True\n",
    "            particle_gamma_fit_model.parameters[\"lambda_H\"].min = -1\n",
    "            #particle_gamma_fit_model.parameters[\"lambda_H\"].min = 1e-5\n",
    "            particle_gamma_fit_model.parameters[\"lambda_H\"].max = 1.0\n",
    "    \n",
    "    else:\n",
    "        particle_gamma_fit_model.parameters[\"e_0L\"].frozen = True\n",
    "        particle_gamma_fit_model.parameters[\"alphaL\"].min = 1.0\n",
    "        particle_gamma_fit_model.parameters[\"alphaL\"].max = 5.0\n",
    "        particle_gamma_fit_model.parameters[\"amplitudeL\"].min = 0\n",
    "    \n",
    "        if(spect_type == 'ECPL'):\n",
    "            particle_gamma_fit_model.parameters[\"betaL\"].frozen = True\n",
    "            particle_gamma_fit_model.parameters[\"betaL\"].frozen = True\n",
    "            particle_gamma_fit_model.parameters[\"lambda_L\"].min = -1\n",
    "            #particle_gamma_fit_model.parameters[\"lambda_L\"].min = 1e-5\n",
    "            particle_gamma_fit_model.parameters[\"lambda_L\"].max = 1.0\n",
    "\n",
    "    return particle_gamma_fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(model, result, label, color):\n",
    "    spec = model.spectral_model\n",
    "    energy_range = [0.1, 160] * u.TeV\n",
    "    spec.plot(\n",
    "        energy_range=energy_range, energy_power=2, label=label, color=color\n",
    "    )\n",
    "    spec.plot_error(energy_range=energy_range, energy_power=2, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_par_profiles(dataset, results):\n",
    "\n",
    "    fit = Fit(dataset, store_trace=True)\n",
    "    total_stat = results[0]\n",
    "    for par in dataset.models.parameters:\n",
    "        if par.frozen is False:\n",
    "            profile = fit.stat_profile(parameter=par)\n",
    "            plt.plot(\n",
    "                profile[f\"{par.name}_scan\"], profile[\"stat_scan\"] - total_stat\n",
    "            )\n",
    "            plt.xlabel(f\"{par.unit}\")\n",
    "            plt.ylabel(\"Delta TS\")\n",
    "            plt.title(f\"{par.name}: {par.value} +- {par.error}\")\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_proton_model(spect_type, norm, index, cutoff, distance, ngas, ep_max):\n",
    "    \"\"\"Normalize the model via the differential flux at 1 TeV (in Crab units), \n",
    "     instead of using the model amplitude, as usually done in Naima.\"\"\"\n",
    "    \n",
    "    crab_unit = \"3.84e-11 cm-2 s-1 TeV-1\" # Crab flux at 1 TeV\n",
    "    \n",
    "    def model_to_be_normalized(x):\n",
    "        \n",
    "        if(spect_type == 'ECPL'):\n",
    "            \n",
    "            particle_distribution = naima.models.ExponentialCutoffPowerLawH(\n",
    "                amplitude=x / u.eV, \n",
    "                e_0=10 * u.TeV, \n",
    "                alpha=index, \n",
    "                lambda_=(1/cutoff) / u.TeV\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            particle_distribution = naima.models.PowerLaw(\n",
    "                amplitude=x / u.eV, \n",
    "                e_0=10 * u.TeV, \n",
    "                alpha=index, \n",
    "            )\n",
    "            \n",
    "        radiative_model = naima.radiative.PionDecay(\n",
    "                particle_distribution,\n",
    "                nh = ngas / u.cm**3,\n",
    "                Epmax = 1e5 * u.PeV,\n",
    "        )\n",
    "        return NaimaSpectralModel(radiative_model=radiative_model, distance=distance*u.kpc)\n",
    "        \n",
    "    def f_pl(x):\n",
    "        a = (model_to_be_normalized(x)(1*u.TeV) / crab_unit).to(\"\") - norm\n",
    "        return a\n",
    "    #amplitude = fsolve(f_pl, 1e32)[0]\n",
    "    amplitude = fsolve(f_pl, 1)[0]\n",
    "    np.testing.assert_almost_equal(f_pl(amplitude), 0)\n",
    "    return model_to_be_normalized(amplitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_electron_model(spect_type, norm, index, cutoff, distance, seed_photon, ee_max):\n",
    "    \n",
    "    crab_unit = \"3.84e-11 cm-2 s-1 TeV-1\" # Crab flux at 1 TeV\n",
    "    \n",
    "    def model_to_be_normalized(x):\n",
    "        \n",
    "        if(spect_type == 'ECPL'):\n",
    "            \n",
    "            particle_distribution = naima.models.ExponentialCutoffPowerLawL(\n",
    "                amplitude=x / u.eV, \n",
    "                e_0=1 * u.TeV, \n",
    "                alpha=index, \n",
    "                lambda_=(1/cutoff) / u.TeV\n",
    "            )\n",
    "        else:\n",
    "            \n",
    "            particle_distribution = naima.models.PowerLaw(\n",
    "                amplitude=x / u.eV, \n",
    "                e_0=1 * u.TeV, \n",
    "                alpha=index, \n",
    "            )            \n",
    "            \n",
    "        radiative_model = naima.radiative.InverseCompton(\n",
    "                particle_distribution,\n",
    "                seed_photon_fields = seed_photon,\n",
    "                Eemax = 1000 * u.TeV,\n",
    "        )\n",
    "        return NaimaSpectralModel(radiative_model=radiative_model, distance=distance*u.kpc)\n",
    "        \n",
    "    def f_pl(x):\n",
    "        a = (model_to_be_normalized(x)(1*u.TeV) / crab_unit).to(\"\") - norm\n",
    "        return a\n",
    "\n",
    "    #amplitude = fsolve(f_pl, 1e32)[0]\n",
    "    amplitude = fsolve(f_pl, 1)[0]\n",
    "    print(f_pl(amplitude))\n",
    "    np.testing.assert_almost_equal(f_pl(amplitude), 0)\n",
    "    return model_to_be_normalized(amplitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_dataset_3D(gammapy_event_file, model_fit):\n",
    "\n",
    "        \"\"\" Fit a 3D dataset assuming a model \"\"\"  \n",
    "        maps = MapDataset.read(gammapy_event_file)\n",
    "        dataset = maps.copy(name=\"dataset-simu\")\n",
    "   \n",
    "        dataset.models = model_fit\n",
    "        model_fit[\"dataset-simu-bkg\"].spectral_model.norm.frozen = False\n",
    "        model_fit[\"dataset-simu-bkg\"].spectral_model.tilt.frozen = True\n",
    "        model_fit[\"diffuse\"].spectral_model.norm.frozen = False\n",
    "        model_fit[\"diffuse\"].spectral_model.tilt.frozen = True\n",
    "        \n",
    "        refit = True\n",
    "        fit_counter = 0\n",
    "        tolerance   = 0.1 \n",
    "\n",
    "        while(refit):\n",
    "            fit = Fit([dataset])\n",
    "            result = fit.run(optimize_opts={\"print_level\": print_level, \"tol\": tolerance, \"strategy\": strategy})\n",
    "            \n",
    "            if(fit_counter == fit_counter_max):\n",
    "                \n",
    "                results_tuple = (\n",
    "                result.total_stat, \n",
    "                False, \n",
    "                result.parameters,\n",
    "                )\n",
    "                print(\"Minimization problem after all trials !\")\n",
    "                return results_tuple, dataset\n",
    "            \n",
    "            if(result.success==True):\n",
    "                print('Minimization successful')\n",
    "                refit = False\n",
    "            else:\n",
    "                fit_counter = fit_counter + 1\n",
    "                tolerance   = tolerance * 2\n",
    "                print('Minimization failed --> Counter = ' + str(fit_counter) + ' increasing tolerance to '+str(tolerance))\n",
    "                continue\n",
    "        \n",
    "        results_tuple = (\n",
    "            result.total_stat, \n",
    "            result.success, \n",
    "            result.parameters,\n",
    "        )\n",
    "\n",
    "        log.info(result.parameters.to_table())\n",
    "\n",
    "        return results_tuple, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_dataset(model, livetime, dataset, background_model, diffuse, norm, index, cutoff):\n",
    "    \"\"\"Simulate n_obs instances of same the 3D dataset\"\"\" \n",
    "    \n",
    "    modelsim = Models([model, background_model, diffuse])\n",
    "        \n",
    "    dataset.models = modelsim\n",
    "\n",
    "    t = int( time.time() * 1000.0 )\n",
    "    tt = ((t & 0xff000000) >> 24) + ((t & 0x00ff0000) >>  8) + ((t & 0x0000ff00) <<  8) + ((t & 0x000000ff) << 24)\n",
    "    log.info(tt)\n",
    "\n",
    "    dataset.fake(random_state=tt)\n",
    "    out_gammapy_event_sim = prefix + 'gammapy_simulation_event_file_proton_norm-'+str(norm)+'_index-'+str(index)+'_cutoff-'+str(cutoff)+'.fits.gz'\n",
    "    dataset.write(out_gammapy_event_sim, overwrite=True)    \n",
    "    return dataset, out_gammapy_event_sim#, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectral_flux_points(e_min, e_max, n_points, dataset, source_name, filename=None):\n",
    "    \n",
    "    # Create spectral bins log equal space between e_min and e_max for n spectral points\n",
    "    # Source name is the name of the component in dataset (see how skymodels are defined, we put names there)\n",
    "    energy_edges = np.logspace(np.log10(e_min), np.log10(e_max), num_points+1) * u.TeV\n",
    "    fpe = FluxPointsEstimator(energy_edges=energy_edges, source=source_name)\n",
    "    flux_points = fpe.run(datasets=dataset)\n",
    "    flux_points.write(filename, overwrite=True)\n",
    "    \n",
    "    return flux_points    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flux_points_and_model(flux_points, model, ul_threshold, energy_power):\n",
    "    \n",
    "    # To plot flux points + model in different ways...\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    flux_points.table[\"is_ul\"] = flux_points.table[\"ts\"] < ul_threshold\n",
    "    ax = flux_points.plot(energy_power=energy_power, flux_unit=\"erg-1 cm-2 s-1\", color=\"darkorange\")\n",
    "    flux_points.to_sed_type(\"e2dnde\").plot_ts_profiles(ax=ax)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    flux_points_dataset = FluxPointsDataset(data=flux_points, models=model)\n",
    "    flux_points_dataset.plot_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WE START THE ANALYSIS BELOW\n",
    "# SET DESIRED SIMULATION & ANALYSIS OPTIONS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/oguzhan/Python3Workspace/CTA_IRFs/fits/Prod5-South-20deg-AverageAz-14MSTs37SSTs.18000s-v0.1.fits.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-be4700d61a3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mirf_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/oguzhan/Python3Workspace/CTA_IRFs/fits/Prod5-South-20deg-AverageAz-14MSTs37SSTs.18000s-v0.1.fits.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mirfs\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mload_cta_irfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mirf_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moffset\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeg\u001b[0m \u001b[0;31m# Simulation offset (degrees)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gammapy/lib/python3.7/site-packages/gammapy/irf/io.py\u001b[0m in \u001b[0;36mload_cta_irfs\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcta_irf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aeff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0maeff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEffectiveAreaTable2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"EFFECTIVE AREA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mbkg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackground3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BACKGROUND\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0medisp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnergyDispersion2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ENERGY DISPERSION\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gammapy/lib/python3.7/site-packages/gammapy/irf/effective_area.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(cls, filename, hdu)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"EFFECTIVE AREA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;34m\"\"\"Read from file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mfits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhdulist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_hdulist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdulist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhdu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gammapy/lib/python3.7/site-packages/astropy/io/fits/hdu/hdulist.py\u001b[0m in \u001b[0;36mfitsopen\u001b[0;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     return HDUList.fromfile(name, mode, memmap, save_backup, cache,\n\u001b[0;32m--> 164\u001b[0;31m                             lazy_load_hdus, **kwargs)\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gammapy/lib/python3.7/site-packages/astropy/io/fits/hdu/hdulist.py\u001b[0m in \u001b[0;36mfromfile\u001b[0;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m         return cls._readfrom(fileobj=fileobj, mode=mode, memmap=memmap,\n\u001b[1;32m    401\u001b[0m                              \u001b[0msave_backup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_backup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                              lazy_load_hdus=lazy_load_hdus, **kwargs)\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gammapy/lib/python3.7/site-packages/astropy/io/fits/hdu/hdulist.py\u001b[0m in \u001b[0;36m_readfrom\u001b[0;34m(cls, fileobj, data, mode, memmap, cache, lazy_load_hdus, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_File\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0;31m# instantiate a FITS file object (ffo)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                 \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m             \u001b[0;31m# The Astropy mode is determined by the _File initializer if the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;31m# supplied mode was None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gammapy/lib/python3.7/site-packages/astropy/utils/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarning_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gammapy/lib/python3.7/site-packages/astropy/io/fits/file.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fileobj, mode, memmap, overwrite, cache)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_fileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_filelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gammapy/lib/python3.7/site-packages/astropy/io/fits/file.py\u001b[0m in \u001b[0;36m_open_filename\u001b[0;34m(self, filename, mode, overwrite)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_read_compressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileobj_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIO_FITS_MODES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_on_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gammapy/lib/python3.7/site-packages/astropy/io/fits/file.py\u001b[0m in \u001b[0;36m_try_read_compressed\u001b[0;34m(self, obj_or_name, magic, mode, ext)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fileobj'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_or_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gzip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.zip'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPKZIP_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gammapy/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/oguzhan/Python3Workspace/CTA_IRFs/fits/Prod5-South-20deg-AverageAz-14MSTs37SSTs.18000s-v0.1.fits.gz'"
     ]
    }
   ],
   "source": [
    "gerrit_simple = False # If true: Fix fit parameters to make things easier in a first place\n",
    "hadronic_true = True # If false: True model is leptonic\n",
    "\n",
    "LIVETIME = 50 * u.hour\n",
    "\n",
    "# Note that before they were 'SouthAz' IRFs, I changed them now to 'AverageAz' IRFs.\n",
    "\n",
    "#irf_filename = (\"fits/Prod5-South-20deg-AverageAz-14MSTs37SSTs.18000s-v0.1.fits.gz\")   \n",
    "irf_filename = (\"/home/oguzhan/Python3Workspace/CTA_IRFs/fits/Prod5-South-20deg-AverageAz-14MSTs37SSTs.18000s-v0.1.fits.gz\")         \n",
    "\n",
    "irfs     = load_cta_irfs(irf_filename)\n",
    "\n",
    "offset   = 0.7 * u.deg # Simulation offset (degrees)\n",
    "distance = 4.0         # Source distance (kpc)\n",
    "ngas     = 10.0        # Gas density for hadronic emission (cm^-3)\n",
    "seed_photon = 'CMB'    # IC seed photon field for leptonic emission. We have 'CMB', 'NIR' and 'FIR' (near or far infrared)\n",
    "\n",
    "# Minuit fit options\n",
    "print_level = 0   \n",
    "strategy    = 2 \n",
    "fit_counter_max = 5\n",
    "\n",
    "prefix = ''\n",
    "diffuse_emission_file = prefix + 'IEM_base_v2.fits'\n",
    "diffuse_model = Map.read(diffuse_emission_file)\n",
    "print(\"DONE READ DIFFUSE...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_max = 1e5 * u.PeV\n",
    "ee_max = 510 * u.TeV #This is default value in naima\n",
    "\n",
    "# HADRONIC SIM MODEL\n",
    "if hadronic_true:\n",
    "    label = 'True Hadronic Model'\n",
    "    norm = 0.1 # Crab unit, so its 100 mCrab (phi_0 at 1 TeV)\n",
    "    index = 2.0\n",
    "    cutoff = 3000\n",
    "    particle_sim_model = create_particle_model('Had','ECPL', norm, index, cutoff, distance, ngas, seed_photon, ep_max, ee_max) #HADRONIC\n",
    "\n",
    "else:\n",
    "# LEPTONIC SIM MODEL\n",
    "    label = 'True Leptonic Model'\n",
    "    norm = 0.1 # Crab unit, so its 100 mCrab (phi_0 at 1 TeV)\n",
    "    index = 3.0\n",
    "    cutoff = 500\n",
    "    particle_sim_model = create_particle_model('Lep','ECPL', norm, index, cutoff, distance, ngas, seed_photon, ep_max, ee_max) #LEPTONIC\n",
    "\n",
    "# Just to plot the gamma-ray model from proton spectrum we want to simulate\n",
    "plt.figure(figsize=(8, 6))\n",
    "energy_range = [0.1,160]*u.TeV\n",
    "energy_power = 2 #(0 for dNdE, 2 for E^2dN/dE)\n",
    "particle_sim_model.plot(energy_range=energy_range, energy_power=energy_power, label=label)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET SOURCE MORPHOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RADEC for LHAASO J1825\n",
    "ra  = 276.45\n",
    "dec = -13.45\n",
    "extension = 0.0 #(Point source)\n",
    "\n",
    "sim_dataset, exposure, background_model, psf, edisp = prepare_cta_irfs(ra, dec)\n",
    "\n",
    "spatial_model_sim, spatial_model_fit = prepare_spatial_models(ra, dec, extension)\n",
    "\n",
    "# Morphology models for particle fit\n",
    "spatial_model_fit_proton_ecpl   = spatial_model_fit.copy()\n",
    "spatial_model_fit_electron_ecpl = spatial_model_fit.copy()\n",
    "# Morphology models for gamma fit\n",
    "spatial_model_fit_gamma_pl      = spatial_model_fit.copy()\n",
    "spatial_model_fit_gamma_ecpl    = spatial_model_fit.copy()\n",
    "spatial_model_fit_gamma_lpb     = spatial_model_fit.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET SIMULATION & ANALYSIS SOURCE MODELS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# SIMULATION MODEL TRUE (source + background + diffuse)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "sky_model_sim = SkyModel(spatial_model=spatial_model_sim, spectral_model=particle_sim_model, name=\"model-simu\")\n",
    "\n",
    "diffuse_roi      = diffuse_model.interp_to_geom(sim_dataset.exposure.geom)\n",
    "diffuse_template = TemplateSpatialModel(diffuse_roi, normalize=False)\n",
    "diffuse          = SkyModel(PowerLawNormSpectralModel(), diffuse_template, name=\"diffuse\")    \n",
    "\n",
    "# --------------------------------------------------\n",
    "# BELOW ARE THE GAMMA-RAY FIT MODELS FOR 3D ANALYSIS\n",
    "# --------------------------------------------------\n",
    "\n",
    "spectral_model_pl_fit, spectral_model_ecpl_fit, spectral_model_lpb_fit = create_gammaray_fit_models()\n",
    "gamma_sky_model_pl   = SkyModel(spatial_model=spatial_model_fit_gamma_pl, spectral_model=spectral_model_pl_fit, name=\"model-fit-gamma-pl\",)\n",
    "gamma_sky_model_ecpl = SkyModel(spatial_model=spatial_model_fit_gamma_ecpl, spectral_model=spectral_model_ecpl_fit, name=\"model-fit-gamma-ecpl\",)\n",
    "gamma_sky_model_lpb  = SkyModel(spatial_model=spatial_model_fit_gamma_lpb, spectral_model=spectral_model_lpb_fit, name=\"model-fit-gamma-lpb\",)\n",
    "\n",
    "gamma_sky_model_pl_full_3d   =  Models([gamma_sky_model_pl, background_model, diffuse])\n",
    "gamma_sky_model_ecpl_full_3d =  Models([gamma_sky_model_ecpl, background_model, diffuse])\n",
    "gamma_sky_model_lpb_full_3d  =  Models([gamma_sky_model_lpb, background_model, diffuse])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# BELOW ARE THE PARTICLE FIT MODELS FOR 3D ANALYSIS\n",
    "# --------------------------------------------------\n",
    "\n",
    "norm_init   = 0.05\n",
    "index_init  = 2.2\n",
    "cutoff_init = 1000\n",
    "\n",
    "proton_model_ecpl_fit      = create_particle_model('Had', 'ECPL', norm_init, index_init, cutoff_init, distance, ngas, seed_photon, ep_max, ee_max)\n",
    "#proton_model_ecpl_fit.parameters[\"lambda_3\"].value  = 1 / 1000\n",
    "#proton_model_ecpl_fit.parameters[\"lambda_3\"].frozen = True\n",
    "if gerrit_simple:\n",
    "    proton_model_ecpl_fit.parameters[\"alphaH\"].value  = index\n",
    "    #proton_model_ecpl_fit.parameters[\"alphaH\"].frozen = True\n",
    "    #proton_model_ecpl_fit.parameters['lambda_H'].value = 1./cutoff\n",
    "    #proton_model_ecpl_fit.parameters['lambda_H'].frozen = True\n",
    "    proton_model_ecpl_fit.parameters[\"lambda_H\"].min = 1 / 5000.\n",
    "    proton_model_ecpl_fit.parameters[\"lambda_H\"].max = 1 / 1.\n",
    "    \n",
    "# Electron model spectral fit models\n",
    "norm_init_lep   = 0.05\n",
    "index_init_lep  = 3.0\n",
    "cutoff_init_lep = 100\n",
    "\n",
    "lepton_model_ecpl_fit      = create_particle_model('Lep', 'ECPL', norm_init_lep, index_init_lep, cutoff_init_lep, distance, ngas, seed_photon, ep_max, ee_max)\n",
    "\n",
    "if gerrit_simple:\n",
    "    lepton_model_ecpl_fit.parameters[\"alphaL\"].value  = index\n",
    "    #lepton_model_ecpl_fit.parameters[\"alphaL\"].frozen = True\n",
    "    #lepton_model_ecpl_fit.parameters['lambda_L'].value = 1./cutoff_init_lep\n",
    "    #lepton_model_ecpl_fit.parameters['lambda_L'].frozen = True\n",
    "    lepton_model_ecpl_fit.parameters[\"lambda_L\"].min = 1 / 5000.\n",
    "    lepton_model_ecpl_fit.parameters[\"lambda_L\"].max = 1 / 1.\n",
    "\n",
    "proton_sky_model_ecpl      = SkyModel(spatial_model=spatial_model_fit_proton_ecpl, spectral_model=proton_model_ecpl_fit, name=\"model-fit-proton-ecpl\",)\n",
    "lepton_sky_model_ecpl      = SkyModel(spatial_model=spatial_model_fit_electron_ecpl, spectral_model=lepton_model_ecpl_fit, name=\"model-fit-lepton-ecpl\",)\n",
    "\n",
    "proton_sky_model_ecpl_full_3d      =  Models([proton_sky_model_ecpl, background_model, diffuse])\n",
    "lepton_sky_model_ecpl_full_3d      =  Models([lepton_sky_model_ecpl, background_model, diffuse])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# BELOW ARE THE PARTICLE FIT MODELS FOR 1D ANALYSIS\n",
    "# -------------------------------------------------\n",
    "\n",
    "spatial_model_fit_proton_ecpl        = spatial_model_fit.copy()\n",
    "proton_model_1d = proton_model_ecpl_fit.copy()\n",
    "lepton_model_1d = lepton_model_ecpl_fit.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WE SIMULATE DATASET FOR TRUE PARTICLE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    dataset_sim, out_gammapy_event_sim = simulate_dataset(sky_model_sim, LIVETIME, sim_dataset, background_model, diffuse, norm, index, cutoff)\n",
    "            \n",
    "except ValueError:\n",
    "             \n",
    "    print(\"We got value error...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WE GO FOR GAMMA RAY ANALYSIS OF THE SIMULATED DATA\n",
    "# WE TEST BETWEEN SPECTRAL MODELS AND CHOOSE THE BEST ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===== Gamma PL Fit to Data ====\")\n",
    "print(\"----------------------\")\n",
    "print(\" Gamma PL 3D Fit \")\n",
    "print(\"----------------------\")\n",
    "gamma_pl, dataset_gamma_pl = fit_dataset_3D(out_gammapy_event_sim, gamma_sky_model_pl_full_3d) \n",
    "print('Likelihood : ', gamma_pl[0])\n",
    "print('Fit Status : ', gamma_pl[1])\n",
    "print(gamma_pl[2].to_table())\n",
    "\n",
    "print(\"===== Gamma ECPL Fit to Data ====\")\n",
    "print(\"----------------------\")\n",
    "print(\" Gamma ECPL 3D Fit \")\n",
    "print(\"----------------------\")\n",
    "gamma_ecpl, dataset_gamma_ecpl = fit_dataset_3D(out_gammapy_event_sim, gamma_sky_model_ecpl_full_3d) \n",
    "print('Likelihood : ', gamma_ecpl[0])\n",
    "print('Fit Status : ', gamma_ecpl[1])\n",
    "print(gamma_ecpl[2].to_table())\n",
    "\n",
    "print(\"===== Gamma LPB Fit to Data ====\")\n",
    "print(\"----------------------\")\n",
    "print(\" Gamma LPB 3D Fit \")\n",
    "print(\"----------------------\")\n",
    "gamma_lpb, dataset_gamma_lpb = fit_dataset_3D(out_gammapy_event_sim, gamma_sky_model_lpb_full_3d) \n",
    "print('Likelihood : ', gamma_lpb[0])\n",
    "print('Fit Status : ', gamma_lpb[1])\n",
    "print(gamma_lpb[2].to_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOME STATISTICS\n",
    "print(\"--------------------------------------\")\n",
    "TS_ecpl_over_pl = gamma_pl[0] - gamma_ecpl[0] \n",
    "print('TS (PL-ECPL) = ', TS_ecpl_over_pl)\n",
    "print('Sigma (PL-ECPL) = ', math.sqrt(TS_ecpl_over_pl))\n",
    "print(\"--------------------------------------\")\n",
    "TS_lpb_over_pl = gamma_pl[0] - gamma_lpb[0] \n",
    "print('TS (PL-LPB) = ', TS_lpb_over_pl)\n",
    "print('Sigma (PL-LPB) = ', math.sqrt(TS_lpb_over_pl))\n",
    "\n",
    "#PLOT GAMMA MODELS\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_spectrum(gamma_sky_model_pl, gamma_pl, label=\"PowerLaw Fit\", color=\"red\")\n",
    "plot_spectrum(gamma_sky_model_ecpl, gamma_ecpl, label=\"ECPL Fit\", color=\"blue\")\n",
    "plot_spectrum(gamma_sky_model_lpb, gamma_lpb, label=\"LogParabola Fit\", color=\"green\")\n",
    "\n",
    "energy_range = [0.1,160]*u.TeV\n",
    "energy_power = 2 #(0 for dNdE, 2 for E^2dN/dE)\n",
    "particle_sim_model.plot(energy_range=energy_range, energy_power=energy_power, label=\"Simulated\" , color=\"black\", ls='--', lw=2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WE OBTAIN SPECTRAL FLUX POINTS USING THE BEST SPECTRAL MODEL\n",
    "# FOR NOW WE JUST TAKE THE BEST MODEL BETWEEN PL AND ECPL\n",
    "# SET BINNING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTIMATE FLUX POINTS FROM THIS MODEL\n",
    "# HOW DO 1D FIT RESULTS EFFECT FROM BINNING ? (CHECK)\n",
    "\n",
    "e_min, e_max = 0.1, 160 # logspace\n",
    "num_points = 10 # Number of flux points we want to have (we can ask for a lot since we have 50h observatios)\n",
    "\n",
    "threshold_ts = 25.0\n",
    "\n",
    "if(TS_ecpl_over_pl > threshold_ts):\n",
    "\n",
    "    source_name = \"model-fit-gamma-ecpl\" # Thats what we defined in SkyModels for hadronic fit\n",
    "    flux_dataset = dataset_gamma_ecpl\n",
    "    file_out = 'test_flux_points_gamma_ecpl.fits'\n",
    "    data_model = gamma_sky_model_ecpl\n",
    "    \n",
    "else:\n",
    "    source_name = \"model-fit-gamma-pl\" # Thats what we defined in SkyModels for hadronic fit\n",
    "    flux_dataset = dataset_gamma_pl\n",
    "    file_out = 'test_flux_points_gamma_pl.fits'\n",
    "    data_model = gamma_sky_model_pl\n",
    "\n",
    "gamma_flux_points = get_spectral_flux_points(e_min, e_max, num_points, flux_dataset, source_name, file_out)\n",
    "\n",
    "# Print out flux points\n",
    "gamma_flux_points.table_formatted\n",
    "\n",
    "#plot stuff if you want\n",
    "ul_threshold = 4 # This is TS, so flux points < 2 sigma significance will be upper limits\n",
    "energy_power = 2\n",
    "plot_flux_points_and_model(gamma_flux_points, data_model, ul_threshold, energy_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_dataset_1D(model, flux_points):\n",
    "\n",
    "    dataset_1d = FluxPointsDataset(model, flux_points)\n",
    "\n",
    "    refit = True\n",
    "    fit_counter = 0\n",
    "    tolerance   = 0.1 \n",
    "    fit_counter_max = 25\n",
    "    strategy = 1\n",
    "\n",
    "    while(refit):\n",
    "        fit_1d = Fit([dataset_1d])\n",
    "        result_1d = fit_1d.run(optimize_opts={\"print_level\": print_level, \"tol\": tolerance, \"strategy\": strategy})\n",
    "        \n",
    "        if(fit_counter == fit_counter_max):\n",
    "                \n",
    "            results_tuple = (\n",
    "            result_1d.total_stat, \n",
    "            False, \n",
    "            result_1d.parameters,\n",
    "            )\n",
    "            print(\"Minimization problem after all trials !\")\n",
    "            return results_tuple\n",
    "            \n",
    "        if(result_1d.success==True):\n",
    "            print('Minimization successful')\n",
    "            refit = False\n",
    "        else:\n",
    "            fit_counter = fit_counter + 1\n",
    "            tolerance   = tolerance * 2\n",
    "            print('Minimization failed --> Counter = ' + str(fit_counter) + ' increasing tolerance to '+str(tolerance))\n",
    "            continue\n",
    "            \n",
    "    results_tuple = (\n",
    "        result_1d.total_stat, \n",
    "        result_1d.success, \n",
    "        result_1d.parameters,\n",
    "    )\n",
    "\n",
    "    return results_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to test 1D particle models fit to flux points\n",
    "# I just read from the written fits file \n",
    "# 1D fit can be quite problematic if we set strategy to 2 (deep fit) and use low tolerance\n",
    "# Strategy 1 works fine in general... \n",
    "\n",
    "flux_points_read = FluxPoints.read(file_out)\n",
    "\n",
    "proton_model_ecpl_1d      = create_particle_model('Had', 'ECPL', norm_init, index_init, cutoff_init, distance, ngas, seed_photon, ep_max, ee_max)\n",
    "lepton_model_ecpl_1d      = create_particle_model('Lep', 'ECPL', norm_init_lep, index_init_lep, cutoff_init_lep, distance, ngas, seed_photon, ep_max, ee_max)\n",
    "\n",
    "proton_model_1d   = SkyModel(spectral_model=proton_model_ecpl_1d)\n",
    "lepton_model_1d    = SkyModel(spectral_model=lepton_model_ecpl_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proton 1d fit\n",
    "print('==== Proton 1D fit results ====')\n",
    "proton_1d_results = fit_dataset_1D(proton_model_1d, flux_points_read)\n",
    "print('Likelihood : ', proton_1d_results[0])\n",
    "print('Fit Status : ', proton_1d_results[1])\n",
    "print(proton_1d_results[2].to_table())\n",
    "\n",
    "#Lepton 1d fit\n",
    "print('==== Lepton 1D fit results ====')\n",
    "lepton_1d_results = fit_dataset_1D(lepton_model_1d, flux_points_read)\n",
    "print('Likelihood : ', lepton_1d_results[0])\n",
    "print('Fit Status : ', lepton_1d_results[1])\n",
    "print(lepton_1d_results[2].to_table())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the composite model after fitting previous two\n",
    "# so it can initialize better (hopefully)\n",
    "\n",
    "#Hadron-initiated composite model components\n",
    "sub_proton_ecpl_1d_h = proton_model_ecpl_1d.copy()\n",
    "sub_lepton_ecpl_1d_h = lepton_model_ecpl_1d.copy()\n",
    "\n",
    "#Lepton-initiated composite model components\n",
    "sub_proton_ecpl_1d_l = proton_model_ecpl_1d.copy()\n",
    "sub_lepton_ecpl_1d_l = lepton_model_ecpl_1d.copy()\n",
    "\n",
    "# Reduce normalization of leptonic component in hadron initiated composite model\n",
    "sub_lepton_ecpl_1d_h.parameters[\"amplitudeL\"].value = sub_lepton_ecpl_1d_h.parameters[\"amplitudeL\"].value/5\n",
    "\n",
    "# Reduce normalization of hadronic component in lepton initiated composite model\n",
    "sub_proton_ecpl_1d_l.parameters[\"amplitudeH\"].value = sub_proton_ecpl_1d_l.parameters[\"amplitudeH\"].value/5\n",
    "\n",
    "#Hadron-initiated composite model\n",
    "composite_model_h = sub_proton_ecpl_1d_h + sub_lepton_ecpl_1d_h\n",
    "composite_model_1d_h = SkyModel(spectral_model=composite_model_h)\n",
    "\n",
    "#Lepton-initiated composite model\n",
    "composite_model_l = sub_proton_ecpl_1d_l + sub_lepton_ecpl_1d_l\n",
    "composite_model_1d_l = SkyModel(spectral_model=composite_model_l)\n",
    "\n",
    "#Composite 1d fit\n",
    "print('==== Composite 1D fit hadron-initialized results ====')\n",
    "composite_1d_h_results = fit_dataset_1D(composite_model_1d_h, flux_points_read)\n",
    "print('Likelihood Had-Ini: ', composite_1d_h_results[0])\n",
    "print('Fit Status Had-Ini: ', composite_1d_h_results[1])\n",
    "print(composite_1d_h_results[2].to_table())\n",
    "\n",
    "print('==== Composite 1D fit lepton-initialized results ====')\n",
    "composite_1d_l_results = fit_dataset_1D(composite_model_1d_l, flux_points_read)\n",
    "print('Likelihood Lep-Ini: ', composite_1d_l_results[0])\n",
    "print('Fit Status Lep-Ini: ', composite_1d_l_results[1])\n",
    "print(composite_1d_l_results[2].to_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "#plot_spectrum(lepton_sky_model_ecpl, lepton_ecpl, label=\"Composite\", color=\"tab:blue\")\n",
    "energy_range = [0.1,160]*u.TeV\n",
    "energy_power = 2 #(0 for dNdE, 2 for E^2dN/dE)\n",
    "particle_sim_model.plot(energy_range=energy_range, energy_power=energy_power, label=\"Simulated\" , color=\"black\", ls='--', lw=2)\n",
    "gamma_flux_points.plot(energy_power=energy_power, color=\"darkorange\")\n",
    "#proton_model_ecpl_1d.plot(energy_range=energy_range, energy_power=energy_power, label=\"Only Hadronic 1D\" , color=\"red\", ls='-', lw=2)\n",
    "#proton_model_ecpl_1d.plot_error(energy_range=energy_range, energy_power=2, color='red')\n",
    "#lepton_model_ecpl_1d.plot(energy_range=energy_range, energy_power=energy_power, label=\"Only Leptonic 1D\" , color=\"blue\", ls='-', lw=2)\n",
    "#lepton_model_ecpl_1d.plot_error(energy_range=energy_range, energy_power=2, color='blue')\n",
    "\n",
    "composite_model_h.plot(energy_range=energy_range, energy_power=energy_power, label=\"Composite 1D-Had\" , color=\"magenta\", ls='-', lw=2)\n",
    "#composite_model_h.plot_error(energy_range=energy_range, energy_power=2, color='magenta')\n",
    "sub_proton_ecpl_1d_h.plot(energy_range=energy_range, energy_power=energy_power, label=\"Sub-Proton H\" , color=\"red\", ls='--', lw=2)\n",
    "sub_lepton_ecpl_1d_h.plot(energy_range=energy_range, energy_power=energy_power, label=\"Sub-Lepton H\" , color=\"blue\", ls='--', lw=2)\n",
    "\n",
    "composite_model_l.plot(energy_range=energy_range, energy_power=energy_power, label=\"Composite 1D-Lep\" , color=\"green\", ls='-', lw=2)\n",
    "#composite_model_l.plot_error(energy_range=energy_range, energy_power=2, color='green')\n",
    "sub_proton_ecpl_1d_l.plot(energy_range=energy_range, energy_power=energy_power, label=\"Sub-Proton L\" , color=\"red\", ls='-.', lw=2)\n",
    "sub_lepton_ecpl_1d_l.plot(energy_range=energy_range, energy_power=energy_power, label=\"Sub-Lepton L\" , color=\"blue\", ls='-.', lw=2)\n",
    "\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test 1:\n",
    "dev_lepton = lepton_1d_results[0]#-2. * np.ln(proton_ecpl[0]) \n",
    "dev_composite = composite_1d_results[0]#-2. * np.ln(composite_ecpl[0])\n",
    "\n",
    "TS_LR1 = np.max([0, dev_lepton - dev_composite])\n",
    "print('TS1='+str(TS_LR1))\n",
    "print('significance for the presence of a hadronic component: ' + str(np.sqrt(TS_LR1))) \n",
    "\n",
    "#Test 2:\n",
    "dev_proton = proton_1d_results[0]#-2. * np.ln(proton_ecpl[0]) \n",
    "dev_composite = composite_1d_results[0]#-2. * np.ln(composite_ecpl[0])\n",
    "\n",
    "TS_LR2 = np.max([0, dev_proton - dev_composite])\n",
    "print('TS2='+str(TS_LR2))\n",
    "print('significance for the presence of a leptonic component: ' + str(np.sqrt(TS_LR2))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BELOW ARE 3D ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proton model fit to simulated data\n",
    "\n",
    "print(\"===== Proton Fit to Data ====\")\n",
    "print(\"----------------------\")\n",
    "print(\" Proton ECPL Free Fit \")\n",
    "print(\"----------------------\")\n",
    "proton_ecpl, dataset_proton_ecpl = fit_dataset_3D(out_gammapy_event_sim, proton_sky_model_ecpl_full) \n",
    "print('Likelihood Free : ', proton_ecpl[0])\n",
    "print('Fit Status Free : ', proton_ecpl[1])\n",
    "print(proton_ecpl[2].to_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOK HOW IF FITS, amplitudeH < 0.1\n",
    "# IF THE FIT IS BAD, REFIT OR RESIMULATE (FOR NOW)\n",
    "# ITS QUITE IMPROTANT TO GET A GOOD FIT FOR THE COMBINED MODEL\n",
    "# MOST OF TIMES YOU CAN GET BETTER FIT, IF YOU REFIT\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "#plot_spectrum(lepton_sky_model_ecpl, lepton_ecpl, label=\"Composite\", color=\"tab:blue\")\n",
    "plot_spectrum(proton_sky_model_ecpl, proton_ecpl, label=\"Hadron\", color=\"tab:blue\")\n",
    "energy_range = [0.1,160]*u.TeV\n",
    "energy_power = 2 #(0 for dNdE, 2 for E^2dN/dE)\n",
    "particle_sim_model.plot(energy_range=energy_range, energy_power=energy_power, label=\"Simulated\" , color=\"black\", ls='--', lw=2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===== Electron Fit to Data ====\")\n",
    "print(\"----------------------\")\n",
    "print(\" Electron ECPL Free Fit \")\n",
    "print(\"----------------------\")\n",
    "lepton_ecpl, dataset_lepton_ecpl = fit_dataset_3D(out_gammapy_event_sim, lepton_sky_model_ecpl_full) \n",
    "print('Likelihood Free : ', lepton_ecpl[0])\n",
    "print('Fit Status Free : ', lepton_ecpl[1])\n",
    "print(lepton_ecpl[2].to_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEPTON FIT TO PURE HADRON IS NOT SO GOOD IN GENERAL, ALTHOUGH FIT IS FINE \n",
    "# CHECK amplitudeL, its actually higher than amplitudeH\n",
    "# (ACTUALLY LAMBDA PREFERS NEGATIVE IN GENERAL, IF YOU CONSTRAIN IT, THE FIT GETS WORST)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_spectrum(lepton_sky_model_ecpl, lepton_ecpl, label=\"Lepton\", color=\"tab:Green\")\n",
    "energy_range = [0.1,160]*u.TeV\n",
    "energy_power = 2 #(0 for dNdE, 2 for E^2dN/dE)\n",
    "particle_sim_model.plot(energy_range=energy_range, energy_power=energy_power, label=\"Simulated\" , color=\"black\", ls='--', lw=2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_par_profiles(dataset_lepton_ecpl, lepton_ecpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW WE CREATE COMPOSITE MODEL FROM FITTED HADRON & LEPTON MODELS \n",
    "# INITIALIZATION OF THESE MODELS SOMEHOW MATTERS IN FIT\n",
    "# Note that these models already carry fit information, one can also copy sure\n",
    "\n",
    "#composite_spectral_model = proton_model_ecpl_fit + lepton_model_ecpl_fit\n",
    "# We have to make copy of this fitted models, then combine (otherwise original fit results change)\n",
    "sub_lepton_model_ecpl_fit = lepton_model_ecpl_fit.copy()\n",
    "sub_proton_model_ecpl_fit = proton_model_ecpl_fit.copy()\n",
    "\n",
    "sub_proton_sky_model_ecpl      = SkyModel(spatial_model=spatial_model_fit_proton_ecpl, spectral_model=sub_proton_model_ecpl_fit, name=\"sub-model-fit-proton-ecpl\",)\n",
    "sub_lepton_sky_model_ecpl      = SkyModel(spatial_model=spatial_model_fit_electron_ecpl, spectral_model=sub_lepton_model_ecpl_fit, name=\"sub-model-fit-lepton-ecpl\",)\n",
    "\n",
    "composite_spectral_model = sub_lepton_model_ecpl_fit + sub_proton_model_ecpl_fit\n",
    "\n",
    "composite_sky_model_ecpl = SkyModel(spatial_model=spatial_model_fit_proton_ecpl, spectral_model=composite_spectral_model, name=\"model-fit-composite-ecpl\",)\n",
    "composite_model_full     =  Models([composite_sky_model_ecpl, background_model, diffuse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF IT PRINTS FALSE AFTER 5 TRIALS, RUN AGAIN THIS CELL (OR INCREASE TOLERANCE IN FIT_DATASET_3D). \n",
    "# IT WILL FIND AN OK FIT, HOPEFULLY.\n",
    "print(\"===== Composite Fit to Data ====\")\n",
    "print(\"----------------------\")\n",
    "print(\" Composite ECPL Free Fit \")\n",
    "print(\"----------------------\")\n",
    "composite_ecpl, dataset_composite_ecpl = fit_dataset_3D(out_gammapy_event_sim, composite_model_full) \n",
    "print('Likelihood Free : ', composite_ecpl[0])\n",
    "print('Fit Status Free : ', composite_ecpl[1])\n",
    "print(composite_ecpl[2].to_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS COMPARES ALL TOGETHER WITH SUBCOMPONENTS\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "energy_power = 2 #(0 for dNdE, 2 for E^2dN/dER\n",
    "energy_range = [0.1,160]*u.TeV\n",
    "particle_sim_model.plot(energy_range=energy_range, energy_power=energy_power, label=\"Simulated\" , color=\"black\", ls='--', lw=2)\n",
    "plot_spectrum(sub_proton_sky_model_ecpl, composite_ecpl, label=\"Hadronic Component\", color=\"tab:Blue\")\n",
    "plot_spectrum(sub_lepton_sky_model_ecpl, composite_ecpl, label=\"Leptonic Componen\", color=\"tab:Green\")\n",
    "plot_spectrum(composite_sky_model_ecpl, composite_ecpl, label=\"Composite\", color=\"tab:Red\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_par_profiles(dataset_composite_ecpl, composite_ecpl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIC model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_proton = proton_ecpl[0]#-2. * np.log(proton_ecpl[0]) # modulo terms which depend on the number of parameters\n",
    "AIC_lepton = lepton_ecpl[0]#-2. * np.log(lepton_ecpl[0]) # modulo terms which depend on the number of parameters\n",
    "\n",
    "# If Delta_AIC > 0, the proton model gives better predictions for the data than the lepton model\n",
    "Delta_AIC = AIC_lepton - AIC_proton # difference is the only relevant quantity, in this case independent from number of parameters\n",
    "print('delta AIC: ' + str(Delta_AIC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composite model selection\n",
    "\n",
    "Test 1:\n",
    "\n",
    "- Null hypothesis: Only leptonic\n",
    "- Alternative hypothesis: There is a hadronic component\n",
    "\n",
    "Test 2:\n",
    "\n",
    "- Null hypothesis: Only hadronic\n",
    "- Alternative hypothesis: There is a leptonic component\n",
    "\n",
    "\n",
    "Note1: Delta_AIC is very close to TS_LR1 if the hadronic model is clearly preferred. This holds by construction, \n",
    "but only if the hadronic model is really clearly preferred.\n",
    "\n",
    "Note2: This is a Likelihood ratio test. There are also other tests. One can disucss all this. Also regarding robustness, i.e. when the true models are neither our simple leptonic nor our simple hadronic models. One idea is to use an F-test again, like in my pevatron HESS GPS paper. One needs spectral points for this instead of likelihoods. But that's a topic for a detailed study, later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test 1:\n",
    "dev_lepton = lepton_ecpl[0]#-2. * np.ln(proton_ecpl[0]) \n",
    "dev_composite = composite_ecpl[0]#-2. * np.ln(composite_ecpl[0])\n",
    "\n",
    "TS_LR1 = np.max([0, dev_lepton - dev_composite])\n",
    "print('TS1='+str(TS_LR1))\n",
    "print('significance for the presence of a hadronic component: ' + str(np.sqrt(TS_LR1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test 2:\n",
    "dev_proton = proton_ecpl[0]#-2. * np.ln(proton_ecpl[0]) \n",
    "dev_composite = composite_ecpl[0]#-2. * np.ln(composite_ecpl[0])\n",
    "\n",
    "TS_LR2 = np.max([0, dev_proton - dev_composite])\n",
    "print('TS2='+str(TS_LR2))\n",
    "print('significance for the presence of a leptonic component: ' + str(np.sqrt(TS_LR2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAYBE ONE CAN JUDGE THE CONTRIBUTION BY CHECKING THE INTEGRAL FLUX ?\n",
    "\n",
    "energy_min = 0.1   * u.TeV \n",
    "energy_max = 160.0 * u.TeV\n",
    "integral_proton = proton_model_ecpl_fit.integral(energy_min=energy_min, energy_max=energy_max)\n",
    "\n",
    "int_proton = integral_proton.value\n",
    "\n",
    "integral_lepton = lepton_model_ecpl_fit.integral(energy_min=energy_min, energy_max=energy_max)\n",
    "\n",
    "int_lepton = integral_lepton.value\n",
    "\n",
    "total = int_proton + int_lepton\n",
    "\n",
    "ratio_hadron = (int_proton/total)*100\n",
    "\n",
    "print(ratio_hadron)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
